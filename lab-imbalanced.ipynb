{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with Credit Card Fraud dataset.\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "- **distance_from_home:** the distance from home where the transaction happened.\n",
    "- **distance_from_last_transaction:** the distance from last transaction happened.\n",
    "- **ratio_to_median_purchase_price:** Ratio of purchased price transaction to median purchase price.\n",
    "- **repeat_retailer:** Is the transaction happened from same retailer.\n",
    "- **used_chip:** Is the transaction through chip (credit card).\n",
    "- **used_pin_number:** Is the transaction happened by using PIN number.\n",
    "- **online_order:** Is the transaction an online order.\n",
    "- **fraud:** Is the transaction fraudulent. **0=legit** -  **1=fraud**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "distance_from_home",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "distance_from_last_transaction",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratio_to_median_purchase_price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "repeat_retailer",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "used_chip",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "used_pin_number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "online_order",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fraud",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1685a384-81ef-4d9c-90c1-ba5a40b91932",
       "rows": [
        [
         "0",
         "57.87785658389723",
         "0.3111400080477545",
         "1.9459399775518595",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "10.829942699255543",
         "0.1755915022816658",
         "1.294218810619857",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "5.091079490616996",
         "0.8051525945853258",
         "0.4277145611942758",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "3",
         "2.2475643282963613",
         "5.60004354707232",
         "0.3626625780570958",
         "1.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "4",
         "44.19093600261837",
         "0.5664862680583477",
         "2.2227672978404707",
         "1.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940              1.0        1.0   \n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "3                        0.362663              1.0        1.0   \n",
       "4                        2.222767              1.0        1.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  \n",
       "3              0.0           1.0    0.0  \n",
       "4              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\")\n",
    "fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** What is the distribution of our target variable? Can we say we're dealing with an imbalanced dataset?\n",
    "- **2.** Train a LogisticRegression.\n",
    "- **3.** Evaluate your model. Take in consideration class importance, and evaluate it by selection the correct metric.\n",
    "- **4.** Run **Oversample** in order to balance our target variable and repeat the steps above, now with balanced data. Does it improve the performance of our model? \n",
    "- **5.** Now, run **Undersample** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model?\n",
    "- **6.** Finally, run **SMOTE** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de la variable objetivo (fraud):\n",
      "fraud\n",
      "0.0    0.912597\n",
      "1.0    0.087403\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "# Miro la distribución de la variable 'fraud' para ver si está desbalanceado\n",
    "# Con normalize=True veo los porcentajes, que es más claro\n",
    "distribucion = fraud['fraud'].value_counts(normalize=True)\n",
    "print(\"Distribución de la variable objetivo (fraud):\")\n",
    "print(distribucion)\n",
    "\n",
    "# Conclusión: Sí, está muy desbalanceado. Más del 91% de los casos son 'no fraude' (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparo los datos para los modelos\n",
    "# X son todas las columnas menos la que quiero predecir\n",
    "X = fraud.drop('fraud', axis=1)\n",
    "# y es la columna que quiero predecir\n",
    "y = fraud['fraud']\n",
    "\n",
    "# Divido los datos en entrenamiento y prueba. \n",
    "# Importante: esta división se hace una sola vez sobre los datos originales.\n",
    "# Las técnicas de balanceo solo se aplicarán a X_train y y_train.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo con datos desbalanceados:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98    273779\n",
      "         1.0       0.90      0.60      0.72     26221\n",
      "\n",
      "    accuracy                           0.96    300000\n",
      "   macro avg       0.93      0.80      0.85    300000\n",
      "weighted avg       0.96      0.96      0.96    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2 y 3\n",
    "\n",
    "# Entreno un modelo de Regresión Logística con los datos originales\n",
    "modelo_original = LogisticRegression(max_iter=1000, random_state=42)\n",
    "modelo_original.fit(X_train, y_train)\n",
    "\n",
    "# Hago predicciones y evalúo\n",
    "predicciones_original = modelo_original.predict(X_test)\n",
    "\n",
    "print(\"Resultados del modelo con datos desbalanceados:\")\n",
    "print(classification_report(y_test, predicciones_original))\n",
    "\n",
    "# Conclusión: La 'accuracy' es muy alta (96%), pero es una métrica engañosa aquí.\n",
    "# Lo importante es el 'recall' para la clase 1 (fraude), que es solo 0.60.\n",
    "# Esto significa que el modelo solo está detectando el 60% de los fraudes reales, se le escapan muchos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo con Oversampling:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    273779\n",
      "         1.0       0.58      0.95      0.72     26221\n",
      "\n",
      "    accuracy                           0.93    300000\n",
      "   macro avg       0.79      0.94      0.84    300000\n",
      "weighted avg       0.96      0.93      0.94    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "# Aplico Oversampling para balancear los datos de entrenamiento\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Entreno un nuevo modelo con los datos balanceados por oversampling\n",
    "modelo_over = LogisticRegression(max_iter=1000, random_state=42)\n",
    "modelo_over.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Evalúo el modelo en el conjunto de test (que sigue desbalanceado, como en la realidad)\n",
    "predicciones_over = modelo_over.predict(X_test)\n",
    "\n",
    "print(\"Resultados del modelo con Oversampling:\")\n",
    "print(classification_report(y_test, predicciones_over))\n",
    "\n",
    "# Conclusión: El 'recall' para la clase 1 ha mejorado de forma espectacular, pasando de 0.60 a 0.95.\n",
    "# Ahora el modelo detecta el 95% de los fraudes. Sin embargo, la 'precision' ha bajado a 0.58,\n",
    "# lo que significa que ahora hay más \"falsas alarmas\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo con Undersampling:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    273779\n",
      "         1.0       0.58      0.95      0.72     26221\n",
      "\n",
      "    accuracy                           0.93    300000\n",
      "   macro avg       0.79      0.94      0.84    300000\n",
      "weighted avg       0.96      0.93      0.94    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "\n",
    "# Aplico Undersampling para balancear los datos de entrenamiento\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Entreno un nuevo modelo con los datos balanceados por undersampling\n",
    "modelo_under = LogisticRegression(max_iter=1000, random_state=42)\n",
    "modelo_under.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Evalúo el modelo\n",
    "predicciones_under = modelo_under.predict(X_test)\n",
    "\n",
    "print(\"Resultados del modelo con Undersampling:\")\n",
    "print(classification_report(y_test, predicciones_under))\n",
    "\n",
    "# Conclusión: Los resultados son idénticos a los de Oversampling.\n",
    "# El 'recall' para la clase 1 también sube a 0.95, mejorando muchísimo la detección de fraudes\n",
    "# a cambio de una menor precisión (0.58)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo con SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    273779\n",
      "         1.0       0.58      0.95      0.72     26221\n",
      "\n",
      "    accuracy                           0.93    300000\n",
      "   macro avg       0.79      0.94      0.84    300000\n",
      "weighted avg       0.96      0.93      0.94    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "\n",
    "# Aplico SMOTE, una técnica de oversampling más avanzada\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Entreno un nuevo modelo con los datos generados por SMOTE\n",
    "modelo_smote = LogisticRegression(max_iter=1000, random_state=42)\n",
    "modelo_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Evalúo el modelo\n",
    "predicciones_smote = modelo_smote.predict(X_test)\n",
    "\n",
    "print(\"Resultados del modelo con SMOTE:\")\n",
    "print(classification_report(y_test, predicciones_smote))\n",
    "\n",
    "# Conclusión: SMOTE también produce los mismos resultados que las otras dos técnicas.\n",
    "# El 'recall' de 0.95 demuestra que es muy efectivo para encontrar fraudes.\n",
    "#\n",
    "# Veredicto final: Las tres técnicas (Oversampling, Undersampling y SMOTE) han mejorado\n",
    "# drásticamente la capacidad del modelo para detectar fraudes, y en este caso,\n",
    "# todas han llegado a un resultado idéntico. Cualquiera de ellas sería una buena elección."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
